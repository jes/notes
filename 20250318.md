# 2025-03-18

## Shader compilation time

This may be the sort of thing where I have to work on something else
and hope to solve it by accident, so I probably shouldn't put off
writing the interval arithmetic stuff much longer.

But today I do want to have one more go at figuring out why my shaders
take so long to compile, or what I can do about it.

The first thing is coming up with a way to ensure
that when I compile a shader it is actually recompiling it rather
than using a cached result. So I think my `map()` function wants to
permute the distance by some compile-time constant? Is that enough?

     float map(vec3 p) {
         p = rotatePoint(p);
         return ${document.shaderCode()} + ${Math.random()};
     }

For a document that is just a single triangle `SketchNode`, it compiles
in 1323 ms (best case out of 6 or so refreshes).

With the in/out test removed, this goes down to 652 ms.

 * All 3 tests: 1323 ms
 * Only first 2 tests: 1103 ms
 * Only final test: 901 ms
 * No tests: 652 ms

In each case reporting the best result out of a bunch of refreshes.
(Rationale for taking the "best" is that other random software stuff can
*slow it down* but can't speed it up, so the fastest time is most
representative of the time that is purely spent on compiling the shader).

So it looks like the compile time grows by about
225 ms per in/out test, apparently linearly.

The test is:

      s *= 1.0 - 2.0 * float((p2d.y >= va.y && p2d.y < vb.y && ds.y > 0.0) ||
                        (p2d.y < va.y && p2d.y >= vb.y && ds.y <= 0.0));

I just don't see how it takes 225 ms to compile that.

What if I run the test twice each time? It will always be a no-op
because `1.0*1.0 == -1.0*-1.0`, but I wonder how it affects compile time.

On the theory above we would expect about `650 + 6 * 225 = 2000 ms`.

Best case I saw was 1773 ms! Which is not *super* far off.

And what if we make a square instead of a triangle? We'd expect maybe
a bit more than 650 ms, plus 4 times 225 = maybe 1600 ms?

Best case was 1777 ms, which is curiously close to 1773 ms before. Is
there some fixed-duration optimisation process or something, and it
increases the amount of time it spends optimising based on the size of
your shader?

ChatGPT told me about something called `WEBGL_debug_shaders` which can
tell you what the GLSL of your "translated" shader looks like.
Which is interesting because I didn't know it was going to be
"translated". I think it basically looks like my original shader but
with all the variables renamed like "webgl_2df94a985cc6c16b".

https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_debug_shaders/getTranslatedShaderSource

ChatGPT suggested rewriting the in/out test as:

      float signCheck = step(va.y, p2d.y) * step(p2d.y, vb.y) * step(0.0, ds.y) +
                  step(vb.y, p2d.y) * step(p2d.y, va.y) * step(ds.y, 0.0);
      s *= 1.0 - 2.0 * signCheck;

And... it now compiles in 175 ms?? I'm pretty sure I tried this before
so I won't count my chickens too early, but that is looking
promising.

It does seem to cause a slight visual glitch though, I think because
it has basically turned a "<=" into a "<" or something. I guess
I subtract `eps` from the first argument?

Oh! A much worse problem is that now if both sides of the disjunction
are true then we get `signCheck == 2.0`.

This works:

      float signCheck = step(va.y, p2d.y) * step(p2d.y, vb.y-eps) * step(0.0, ds.y) +
                  step(vb.y, p2d.y) * step(p2d.y, va.y-eps) * step(ds.y, 0.0);
      s = mix(s, -s, min(1.0, signCheck));

Great, so now the default object compiles in 1000 ms instead of 1900 ms.
So there is more to do. But the document with just a triangle sketch
is down from 1323 ms to 176 ms.

So what else in the default document is slow?

Starting from 1000 ms, how much do I lose when I delete each thing:

 * Sketch: 200 ms
 * Box: 150 ms
 * Extrude: 140 ms
 * DistanceDeform: 130 ms
 * Transform (rotate): 120 ms
 * Sphere: 120ms
 * Torus: 75 ms
 * Thickness: 20 ms
 * Transform (translate): ~0 ms

So the Sketch is still the most expensive part.

OK, and if I start with a blank document, how much does compilation time
grow when I *add* each thing?

 * empty: 9 ms
 * Box: 215 ms
 * Box+Sphere: 277 ms
 * Sphere: 184 ms
 * Torus: 198 ms
 * Box+Torus: 324 ms
 * Sphere+Torus: 264 ms
 * Box+Sphere+Torus: 391 ms

A union of 0 objects is a no-op. Union of 1 object is free because
the generated code is a straight pass-through. Union of
2 objects is one `min()` operation, and union of 3 objects is 2 `min()`
operations.

But somehow adding a second object increases the overhead by less than
adding the first object did.

It's pretty crazy that a document with just a sphere takes 184 ms
to compile when the empty document only takes 9 ms, because the
sphere code is just `length(p) - r`.

It would be really good if I could somehow statically compile the
ray marching code and lighting code etc., and just recompile the SDF
when it changes. Isn't that what `gl.linkProgram()` is meant to be for?
But I couldn't get it to work last time I tried.

Cursor insists that it is meant to be possible.

## Multisampling

The multisampling doesn't actually seem to be working very well,
it is giving jaggy edges even though resolution scale is about 7.5.

https://img.incoherency.co.uk/6059

Do I need to make the canvas bigger than the viewport in order to get the
benefit?
