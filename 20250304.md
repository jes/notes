# 2025-03-04

## Signed Distance Fields

I've been lying awake toying with the idea of making a SDF-based CAD program.

There are only 2 things I want to do with a CAD model:

 * draw it on the screen
 * 3d print it

If we say that an object in our CAD is represented by an anonymous function
of `(x,y,z)` that returns the distance from that point to the nearest point of our
object (negative if inside the object), then we have:

    sphere(r) = func(x,y,z) x^2+y^2+z^2 - r^2
    union(f1, f2) = func(x,y,z) min(f1(x,y,z), f2(x,y,z))
    intersection(f1, f2) = func(x,y,z) max(f1(x,y,z), f2(x,y,z))
    cut(f1, f2) = func(x,y,z) f1(x,y,z) - f2(x,y,z)
    halfspace(z) = func(x,y,z) z
    cube(w,h,l) = func(x,y,z) max(x-w, y-h, z-l, w-x, h-y, l-z)
    translate(f,dx,dy,dz) = func(x,y,z) f(x-dx,y-dy,z-dz)

And so on. You can also imagine a "sketch" feature that lets you define a SDF
of only 2 dimensions with some Sketcher-like interface, which is then effectively
an infinite extrusion of your shape (considering that you disregard `z`), and to
pad it you intersect it with a slice of `z` covering the range you want, and union
with the existing part.

Benefits over traditional CAD are that it has much fewer edge cases so more likely to
get it correct in less time, makes some cool operations easy that traditional CAD
doesn't, and makes complex intersections etc. really fast to calculate.

The main downsides are that rendering is potentially complicated, not sure, I need to
find this out, and any workflow that involves selecting vertices and edges is
really hard to do.

So for a toy prototype you need a basic UI for specifying these objects,
a way to render them on screen, and a way to 3d print them.

I'm not fussed whether 3d printing works by exporting a triangle mesh or by slicing
directly from SDF. But it seems like if you can slice directly from SDF then you can
make a triangle mesh almost as easily, and then you get the benefits of a "real"
slicer.

Also slicing to triangle mesh would solve the rendering-on-screen problem at the same
time, so maybe that's the way to go.

For rendering, ChatGPT suggests:

 * ray marching (for each pixel, march a ray forwards into the scene until you strike the object)
 * voxelised ray marching (the same but you precompute a "sparse voxel octree" to make it faster)
 * marching cubes (for turning into a triangle mesh)

You can do ray marching in a shader, but the one downside there is that we've
basically made "recompute" really fast by just making each operation a tiny function,
but now our real recompute is *every single frame* as we have to evaluate the
function.

You could imagine some scheme where we do a few passes of ray marching on
progressively higher-resolution grids until we reach full screen resolution, and if the
user is still moving the object around and a frame is due we just draw the highest
resolution image we have. That way in steady state it will improve over time until
it is rendered at full resolution, but you can still move around fluidly, as long as
you accept a worse-quality image while you're doing it.

Not sure if anyone has done a CAD-like user interface for SDF modelling yet.

Interesting prior art:

 * https://github.com/deadsy/sdfx
 * https://github.com/fogleman/sdf
 * https://f-rep.org/frep/main

Other resources:

 * https://iquilezles.org/articles/distfunctions/
 * https://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/
 * https://en.wikipedia.org/wiki/Function_representation
 * https://core.ac.uk/download/pdf/189216004.pdf

One thing that makes it more tricky than I imagined is if your distances are
wrong then some operations won't work properly. For example if you scale something
by doing `scale(f, k) = func(x,y,z) f(x/k, y/k, z/k)` then the distances are not scaled
as well, so then if you do some operation that actually cares about the distance (like
a "thickness" for example) then the thickness will be wrong.

For a uniform scale I think you could do `scale(f,k) = func(x,y,z) k * f(x/k, y/k, z/k)`.
but for non-uniform scale I'm not sure how you'd do it.

For applying fillets I wonder if you could "detect" edges for the user to click on
by looking for places that
have sharp changes in the normal direction, and then apply some modification to the
SDF that is bounded to a region near the edge? The "sharpness" threshold could be
configurable.

So you can tell that a *point* is sharp if it has normal direction very different to
any nearby points. And you can tell that a point is part of a *line* if there is a nearby
point that also has high sharpness.

So maybe you'd work out what point the mouse is hovering over, work out if there is
sharpness nearby, and then spread out to find the edge(s), and then highlight the
detected edge(s) as the place that the fillet will be applied?

The Wikipedia page on "Function representation" takes a simpler form, where the
actual distance value is not required to be accurate. That means we have more freedom to
do operations that distort the function, but no longer can use the distance for
productive purposes. Maybe in practice it is just the same thing, because I can't
see how you can do much of any use with the function representation otherwise.
