# 2025-04-03

## Volume, mass, centre of mass

Today I had some thoughts on calculating volume, mass, and centre of mass
of SDFs:

 * implement the SDF solely out of continuous primitives (so, for step function etc., use "smooth" versions that change very rapidly, make smooth approximations for all discontinuous functions)
 * wrap your SDF in a smooth approximation of "f(x,y,z) < 0 ? 1 : 0" to get a function that gives 1 inside the object and 0 outside
 * use automatic integration to turn it into a function that tells you "how many 1s" are inside the object - this gives you its volume
 * and then instead of just getting out 1 or 0 at the top level, propagate material densities up the tree (same as for surface ids etc.) and then it becomes "f(x,y,z) < 0 ? density : 0", and then the integral of that is mass
 * for each axis, binary search to find the plane in that axis that divides the mass in half: the intersection of these planes is the centre of mass

Apparently it is not easy to do automatic integration analytically.

ChatGPT says that if we have automatic integration then we
can compute the centre of mass in each axis directly, as the integral of
"the coordinate in that axis multiplied by the density at that point",
and then dividing by the overall mass.

    COM_x = integral(integral(integral(x * density(x,y,z) dx)dy)dz) / mass

I guess we have to do integrals with numerical methods. You can use
interval arithmetic to easily classify large volumes as inside or
outside, and then recursive subdivision to work out how much is
actually in or out, and stop when enough significant figures seem
stable.

## Surface queries

Work out what types of object you might want to query (primitives, sub-primitive surfaces, sub-root objects in tree, only modifiers, etc.), and tag each `struct` with ids for all of those things, and let users choose their selection mode. Also allow fillets between any pair of things (so you could do a fillet between "Sphere001" and "Box001_Surface002" for example).

The only combinator that needs to know about the fillet is the most recent common ancestor of the selected surfaces.

The plan is to work out what types of object you might want to query,
which could be "primitives" (Box, Sphere), "basic surfaces" (6 surfaces
of a box), "top-level objects" (everything immediately under Document),
"modifiers", "combinators", some special type of tagged objects?

And then the expression tree needs to propagate a separate id for each
type of thing you might want to query.

And then by changing your "selection mode" (is there a better way?) you
can do surface queries by clicking on the object, and then apply fillets
between any 2 selected things - and they wouldn't even have to be of
the same type. You could easily fillet between a particular surface and
a particular top-level object.

And although we obviously could build up a massive expression to
calculate all possible combinations of object to find the blend radius...
we actually only need to put the interaction between 2 objects in
their *first common ancestor*. Because that is the only node that can
see surfaces of both types.

Because in order to get an interaction between 2 surfaces in a `min`/`max`, you
need to have one surface on one side and one surface on the other.

## Clockwatcher

Not sure what has happened, but it has some datapoints showing
absolutely enormous period, even with other datapoints
either side showing really short periods:

https://img.incoherency.co.uk/6099

And that's with moving average turned on!

How can there be a 15k second period and yet it took less than 15k
seconds until the next sample?

https://img.incoherency.co.uk/6100

Some massive timestamp drift here. 100B microseconds is a jump of
100k seconds? Which is more than a day. So what happened there?

Has my Raspberry Pi just had bad timestamps due to being turned off
for too long, and it gave up on trying to smudge it and instead just
did a couple of step changes? I don't really understand.

At about the same timestamps there are also discontinuities in
the pressure and humidity readings, and to a lesser extent in
the temperature:

https://img.incoherency.co.uk/6101

That the problem afflicts some sensors apart from the balance wheel
position sensor suggests that the timestamp problem is inside the Pi
and not the ESP32 (because the environmental sensors are connected
directly to the Pi).

OK, I think it is a data loading problem of some sort!

If you draw a straight line through the timestamp drift points:

https://img.incoherency.co.uk/6102

You can see it intersects the origin!

That suggests that at those points we got a timestamp of 0?

And the values in the pressure, temperature, and humidity charts
*also* show the same value as the value at timestamp 0.

https://img.incoherency.co.uk/6103

So that is very interesting.

For some reason we're inserting duplicate copies of the very
first datapoint, either in the database or in the chart. Potentially
the database is getting `NULL`s inserted and the AI JavaScript trash
code is copying the first datapoint in that case?
