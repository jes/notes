# 2025-03-24

## Meshing

For a first pass, just do straightforward marching cubes in some
fixed volume and save out an STL file.

Then:

 * automatically discover the bounding volume somehow (tracking centres would help, bounding volumes would be better)
 * use a sparse octree, and interval evaluation to quickly discard large empty/full regions
 * something better than marching cubes?

OK, wow, Claude is writing out this entire thing off the top of its head,
including the data tables for marching cubes.

I wonder if it is making mistakes here, or it has memorised the characters
it needs to write, or it recognises the structure of the algorithm so it
is deriving it on-the-fly?

Damn, Anthropic cut it off before it finished.

I pasted what it did and asked it to complete it and it got cut off
early again!

I wonder if they think this is some kind of model abuse?

https://img.incoherency.co.uk/6066

If I just ask it to add a few lines at a time it is working.

Meh, I'll just copy from https://gist.github.com/dwilliamson/c041e3454a713e58baf6e4f8e5fffecd

First export of default model looks like this: https://img.incoherency.co.uk/6067

I can *kind of* recognise that this has some triangles in places that
correspond to the default model. It's obviously not working though.

OK, big improvement from mucking about with Cursor:

https://img.incoherency.co.uk/6068

Can now very clearly recognise the shape, though it still has a few
holes in it.

Looking at just this section: https://img.incoherency.co.uk/6069

It is obvious that a lot of the triangles are being placed correctly,
but one of them isn't joining up. So is the triangle table from that
github gist wrong? Or my code is wrong?

ChatGPT suggested logging for "skipping degenerate triangle", and indeed
it is logging a lot of this. So that can easily explain why some triangles
are missing.

At higher resolution we can see it is basically right, just with
holes in it: https://img.incoherency.co.uk/6070

It also looks like half of them might have inverted normals.

OK, Claude-3.7-sonnet-thinking has fixed the normals. Still have half
the triangles missing:

https://img.incoherency.co.uk/6071

By disabling vertex interpolation I get a very blocky mesh that makes
it easier to work out which triangles are missing:

https://img.incoherency.co.uk/6072

Flat faces perpendicular to X seem to be handled properly. Some
triangles are missing on flat faces perpendicular to Y. All triangles
are missing on flat faces perpendicular to Z.

I gave that description to Claude, and a copy-paste of the comment
from the github gist describing the ordering, and it managed to fix
it:

https://img.incoherency.co.uk/6073

Great success!

It is truncated because the bounding volume for the voxel evaluation is
too small.

And both binary and ASCII STL exporting seems to be working
correctly.

Gyroid sphere: https://img.incoherency.co.uk/6074

The binary STL file for the gyroid sphere is 21 megabytes and it took
about 3 seconds to generate.

I think we could improve on the time spent to generate it by using the
sparse voxel octree thing to cut down on the number of cubes. Probably
wouldn't decrease the file size though, because it genuinely is curved
everywhere. But I probably don't care about the file size.

## First Isoform 3d print

Now that I have meshing, let's print something!

https://img.incoherency.co.uk/6077

This is a half-capsule with a shell of a gyroid subtracted from it.
That means it is actually 2 disconnected parts.

https://img.incoherency.co.uk/6076

## Node types

I might want to use wrap/unwrap like in https://github.com/jes/stlwrap

Also some way to create text.

How could I create something like a 2d text node or a sketch node, and
then "fit" it to a surface? Maybe you could approximate it with
"Distance Deform Inside"? Extrude your text really far, make sure the
extrusion goes into the surface, and then "Distance Deform Inside" to
make the surface bulge outwards/inwards where the text intersects it?

Kind of a crude tool. Maybe crude tools is just the nature of SDFs.

Also "Pattern along transformed domain". I guess like LinearPattern,
but it somehow references a "Modifer" tree, but the eventual child of
the modifier tree is not an SDF but is just something that captures
the transformed coordinate so that it knows where to place the object.

Still need to figure out the UI for selecting modifier trees.
I think primitives and combinators don't make any sense in this context,
so restricting it to modifiers is correct. I guess you attach
a modifier tree with no eventual leaf primitive, and then somehow
when you evaluate it you just capture out the transformed coordinate.

In fact it's tighter than just modifier nodes: they need to be
*domain* modifying nodes. Some modifiers only modify the distance,
and they would have no effect here. Maybe a way for a node to flag
itself as a domain modifier?

Also, I should make the nodes somehow register themselves somewhere so
that I don't have to explicitly list them all in the UI thing that makes
the context menu.
